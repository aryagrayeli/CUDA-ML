Layers: 4
784 -> 1000 (sigmoid) -> 500 (sigmoid) -> 10 (softmax)
Train: train_data
Test: test_data
Checkpoint: weights.pth
Epochs: 20  
Batch Size: 128
Alpha: 0.01
Epsilon: 0.01
Loss: CrossEntropy